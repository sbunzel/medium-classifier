{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General steps:\n",
    "\n",
    "- Split into train and test set (random and stratified, using sklearn train_test_split)\n",
    "- Learn transformations and word -> token mapping on train set \n",
    "- Train model on train set (potentially train severals model on different subsets and choose the best one / ensemble their predictions, in the latter case calculate out of bag score as well)\n",
    "- Calculate performance on train set (custom performance metric - choose threshold to get precision to >95% and evaluate recall based on that)\n",
    "- Apply transformations on test set, make predictions and evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:19:33.873941Z",
     "start_time": "2018-11-01T11:19:22.099564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# debugging\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# file system navigation\n",
    "from pathlib import Path\n",
    "\n",
    "# data transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ml algorithms and evaluation metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "# sklearn specifics\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# nlp\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.pipeline import TextCategorizer\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "\n",
    "# misc\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Custom functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:23:04.225886Z",
     "start_time": "2018-11-01T11:23:04.173593Z"
    },
    "code_folding": [
     8,
     29,
     46
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_precision:float=0.95, pos_label:int=1):\n",
    "        self.target_precision = target_precision\n",
    "        self.pos_label = pos_label\n",
    "    \n",
    "    def print_npos(self, y_true:ndarray):\n",
    "        if self.pos_label not in np.unique(y_true):\n",
    "            warnings.warn(f\"Label '{self.pos_label}' is not in test set.\")\n",
    "        else:\n",
    "            npos = np.sum(y_true == self.pos_label)\n",
    "            print(f\"N POSITIVE CLASS: {npos} ({npos / len(y_true)*100:.2f}%)\")\n",
    "        \n",
    "    def score(self, y_true:ndarray, probas_pred:ndarray, display_results:bool=True):\n",
    "        #self.print_npos(y_true) # Log number of positive examples in the current test set\n",
    "        prs, rcs, ths = metrics.precision_recall_curve(y_true, probas_pred, pos_label=self.pos_label)\n",
    "    \n",
    "        if display_results:\n",
    "            auc = metrics.roc_auc_score(y_true, probas_pred)\n",
    "            print(f\"AUC SCORE: {auc:.2f}\")\n",
    "            results = pd.DataFrame({\"precision\": prs[:-1], \"recall\": rcs[:-1], \"threshold\": ths})\\\n",
    "                        .sort_values(by=[\"precision\", \"recall\"], ascending=[False, False])\n",
    "            if np.max(results.precision) > self.target_precision:\n",
    "                print(results[results.precision >= self.target_precision])\n",
    "            else:\n",
    "                print(results.head(3))\n",
    "\n",
    "    def score_extensive(self, y_true:ndarray, probas_pred:ndarray, display_results:bool=False):\n",
    "        self.print_npos(y_true) # Log number of positive examples in the current test set\n",
    "        prs, rcs, ths = metrics.precision_recall_curve(y_true, probas_pred, pos_label=self.pos_label)\n",
    "        \n",
    "        tmp_min_th = np.min(np.append(ths, 1.)[np.where(prs >= self.target_precision)])\n",
    "        min_th = tmp_min_th if tmp_min_th < 1. else np.min(ths)\n",
    "        res_pr = np.max(prs[np.where(ths == min_th)])\n",
    "        res_rc = np.max(rcs[np.where(ths == min_th)])\n",
    "        auc = metrics.roc_auc_score(y_true, probas_pred)\n",
    "        \n",
    "        self.print_results(min_th, res_pr, res_rc, auc) # Log resulting threshold, precision, recall and auc\n",
    "\n",
    "        if display_results:\n",
    "            display(pd.DataFrame({\"Precision\": prs[:-1], \"Recall\": rcs[:-1], \"Threshold\": ths})\\\n",
    "                    .sort_values(by=\"Precision\", ascending=False))\n",
    "            \n",
    "                \n",
    "    def print_results(self, min_th, res_pr, res_rc, auc):\n",
    "        print(f\"MINIMAL THRESHOLD: {min_th:.2f}\")\n",
    "        print(f\"RESULTING PRECISION: {res_pr:.2f} (Target: {self.target_precision})\")\n",
    "        print(f\"RESULTING RECALL: {res_rc:.2f}\")\n",
    "        print(f\"RESULTING AUC: {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:23:05.085899Z",
     "start_time": "2018-11-01T11:23:05.050939Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ScoredClf = namedtuple(\"ScoredClf\", [\n",
    "    \"clf\",\n",
    "    \"train_auc\",\n",
    "    \"oob_auc\"\n",
    "])\n",
    "\n",
    "def fit_ensemble(m, s:StratifiedShuffleSplit, X:ndarray, y:ndarray, **kwargs):\n",
    "    \"\"\"Fit a model on different subsets of the training set and collect the results\n",
    "    \n",
    "    Arguments:\n",
    "    m - a model object implementing `fit` and `predict_proba`\n",
    "    s - an object of class sklearn.model_selection.StratifiedShuffleSplit, i.e. an iterator of random, stratified splits\n",
    "    X - numpy array of training texts\n",
    "    y - numpy array of training labels\n",
    "    **kwargs - keyword arguments to pass to the model when calling fit\n",
    "    \n",
    "    Returns:\n",
    "    fitted_clfs - a list of named tuples collecting the scored classifiers as well as their training and out of bac AUCs\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fitted_clfs = []\n",
    "\n",
    "    for i, split in enumerate(s.split(X, y)):\n",
    "        i_train = split[0]\n",
    "        i_test = split[1]\n",
    "        \n",
    "        print(\"#######################################\")\n",
    "        print(\"Training model number  \", i+1)\n",
    "        print(\"#######################################\")\n",
    "        print(\"\")\n",
    "\n",
    "        m.fit(X[i_train], y[i_train], **kwargs)\n",
    "        fitted_clf = copy.deepcopy(m)\n",
    "        \n",
    "        p1_train = fitted_clf.predict_proba(X[i_train])[:, 1]\n",
    "        p1_oob = fitted_clf.predict_proba(X[i_test])[:, 1]\n",
    "        \n",
    "        train_auc = metrics.roc_auc_score(y[i_train], p1_train)\n",
    "        oob_auc = metrics.roc_auc_score(y[i_test], p1_oob)\n",
    "        fitted_clfs.append(ScoredClf(fitted_clf, train_auc, oob_auc))\n",
    "        \n",
    "        print(\"PERFORMANCE ON TRAIN\")\n",
    "        print(\"\")\n",
    "        evaluator.score(y[i_train], p1_train)\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"OOB PERFORMANCE\")\n",
    "        print(\"\")\n",
    "        evaluator.score(y[i_test], p1_oob)\n",
    "        \n",
    "        print(\"\")\n",
    "    \n",
    "    return fitted_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:23:07.150017Z",
     "start_time": "2018-11-01T11:23:07.131999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_ensemble(fitted:list, eval:CustomEvaluator, X_test:ndarray):\n",
    "    \"\"\"Evaluate the performance of a set of classifier trained on different subsets of the training set\n",
    "    \n",
    "    Arguments:\n",
    "    fitted - list of named tuples containing fitted models as well as their train and out of bag AUC\n",
    "    eval - object of class CustomEvaluator used to evaluate the performance on the hold out set\n",
    "    X_test - numpy array of the texts for the hold out set for final evaluation\n",
    "    \n",
    "    Return:\n",
    "    None - the function is just useful for its side effects\n",
    "    \"\"\"\n",
    "    train_scores = [m.train_auc for m in fitted]\n",
    "    oob_scores = [m.oob_auc for m in fitted]\n",
    "    preds_test = np.array([m.clf.predict_proba(X_test)[:, 1] for m in fitted])\n",
    "\n",
    "    print(f\"Mean Train AUC: {np.mean(train_scores):.2f} (+/- {np.std(train_scores):.2f})\")\n",
    "    print(f\"Mean OOB AUC: {np.mean(oob_scores):.2f} (+/- {np.std(oob_scores):.2f})\")\n",
    "    print(\"\")\n",
    "    print(\"Performance on hold out set:\")\n",
    "    eval.score(y_test, preds_test.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_scores(model, X, y, n_cv=10):\n",
    "    precision_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"precision\")\n",
    "    recall_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"recall\")\n",
    "    print(f\"Average precision score for {n_cv} splits: {precision_scores.mean():.2f} (+/- {precision_scores.std():.2f})\")\n",
    "    print(f\"Average recall score for {n_cv} splits: {recall_scores.mean():.2f} (+/- {recall_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:23:53.465807Z",
     "start_time": "2018-10-21T16:23:53.459929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_score_auc(model, X, y, n_cv=10):\n",
    "    auc_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"roc_auc\")\n",
    "    print(f\"Average auc score for {n_cv} splits: {auc_scores.mean():.2f} (+/- {auc_scores.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:42.909551Z",
     "start_time": "2018-10-23T16:13:42.903097Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_auc(model, X, y, n_cv=10):\n",
    "    auc_cv = cross_validate(model, X, y,\n",
    "                                scoring=\"roc_auc\",\n",
    "                                cv=n_cv,\n",
    "                                n_jobs=-1,\n",
    "                                return_train_score=False,\n",
    "                                return_estimator=True)\n",
    "    auc_scores = auc_cv[\"test_score\"]\n",
    "    mean_auc = auc_scores.mean()\n",
    "    representative_estimator = auc_cv[\"estimator\"][np.argmin([np.abs(score - mean_auc) for score in auc_scores])]\n",
    "    print(f\"Average auc score for {n_cv} splits: {mean_auc:.2f} (+/- {auc_scores.std():.2f})\")\n",
    "    \n",
    "    return representative_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:49:35.059330Z",
     "start_time": "2018-10-21T16:49:35.049853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(model, X, y):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "    step_kwargs = {\"step\": \"post\"}\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where=\"post\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load preprocessed data and make split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:41:42.969537Z",
     "start_time": "2018-11-01T11:41:41.838651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path.cwd() / \"data\" / \"processed\" / \"train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:41:43.511717Z",
     "start_time": "2018-11-01T11:41:43.478510Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:41:53.990101Z",
     "start_time": "2018-11-01T11:41:53.935280Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[[\"claps\", \"reading_time\", \"text\"]]\n",
    "y = np.array(data[\"interesting\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3, random_state=12,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:42:02.678163Z",
     "start_time": "2018-11-01T11:42:02.656353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluator = CustomEvaluator(target_precision=0.8)\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=6, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:16.555610Z",
     "start_time": "2018-10-23T16:13:16.549837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_base = data[[\"claps\", \"reading_time\", \"interesting\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Visualize data distribution for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(wd, \"output\", \"base_classifier.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Baseline classficiation model using author, claps and reading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T21:48:39.703145Z",
     "start_time": "2018-10-26T21:48:39.683201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_cols = [\"claps\", \"reading_time\"]\n",
    "X_train_num, X_test_num = np.array(X_train[num_cols]), np.array(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T21:48:39.907141Z",
     "start_time": "2018-10-26T21:48:39.899842Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T21:48:43.029345Z",
     "start_time": "2018-10-26T21:48:42.545697Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted = fit_ensemble(rf, sss, X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T21:51:14.273201Z",
     "start_time": "2018-10-26T21:51:14.170745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted, evaluator, X_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:56.804070Z",
     "start_time": "2018-10-23T16:13:53.798814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_model = get_cv_auc(RandomForestClassifier(), X_num, y, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:21:28.607292Z",
     "start_time": "2018-10-23T16:21:28.601934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = model_selection.StratifiedShuffleSplit(n_splits=4, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:32:32.143735Z",
     "start_time": "2018-10-23T16:32:32.073254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, split in enumerate(s.split(X_num, y_num)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    print(\"Training model number  \", i)\n",
    "    rf_model.fit(X_num.iloc[i_train, :], y_num[i_train])\n",
    "    print(\"AUC on the test set:\")\n",
    "    print(metrics.roc_auc_score(y_num[i_test], rf_model.predict_proba(X_num.iloc[i_test, :])[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:42:11.206584Z",
     "start_time": "2018-11-01T11:42:11.190292Z"
    }
   },
   "outputs": [],
   "source": [
    "text_col = \"text\"\n",
    "X_train_text, X_test_text = np.array(X_train[text_col]), np.array(X_test[text_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T12:45:20.557778Z",
     "start_time": "2018-10-24T12:45:20.552611Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"interesting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create true hold out set to simulate future articles coming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:20:47.213764Z",
     "start_time": "2018-10-24T13:20:47.208360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_text[0:70]\n",
    "y_70 = y[0:70]\n",
    "\n",
    "X_100 = X_text[70:]\n",
    "y_100 = y[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:24:47.508398Z",
     "start_time": "2018-10-24T13:24:47.496691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_70.reset_index().drop(\"index\", axis=1)[\"text\"]\n",
    "X_100 = X_100.reset_index().drop(\"index\", axis=1)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:25:34.020042Z",
     "start_time": "2018-10-24T13:25:34.009723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_70 = y_70.reset_index().drop(\"index\", axis=1)[\"interesting\"]\n",
    "y_100 = y_100.reset_index().drop(\"index\", axis=1)[\"interesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T17:16:28.204341Z",
     "start_time": "2018-10-23T17:16:28.198673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text,\n",
    "                                                              y,\n",
    "                                                              test_size=0.3,\n",
    "                                                              random_state=42,\n",
    "                                                              stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:42:33.821781Z",
     "start_time": "2018-11-01T11:42:33.807829Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:42:37.240343Z",
     "start_time": "2018-11-01T11:42:37.226526Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe_countvec = make_pipeline(count_vectorizer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:42:43.366342Z",
     "start_time": "2018-11-01T11:42:39.552617Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_countvec = fit_ensemble(pipe_countvec, sss, X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:43:04.929536Z",
     "start_time": "2018-11-01T11:43:04.079736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_countvec, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:58.877105Z",
     "start_time": "2018-10-21T17:10:56.454940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:59.048427Z",
     "start_time": "2018-10-21T17:10:58.880179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Some optimization, i.e. preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:29.267522Z",
     "start_time": "2018-10-21T17:09:29.256534Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", CountVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000)}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=8,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=10,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.021782Z",
     "start_time": "2018-10-21T17:09:32.004989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = grid.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.032580Z",
     "start_time": "2018-10-21T17:09:50.025314Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_auc = grid.cv_results_[\"mean_test_score\"].mean()\n",
    "std_auc = grid.cv_results_[\"std_test_score\"].mean()\n",
    "print(f\"Average auc score: {avg_auc:.2f} (+/- {std_auc:.2f})\")\n",
    "# pd.DataFrame.from_dict(grid.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.477014Z",
     "start_time": "2018-10-21T17:09:50.036911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(grid.best_estimator_, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:27:12.220276Z",
     "start_time": "2018-11-01T13:27:12.136695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "??RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:27:38.038274Z",
     "start_time": "2018-11-01T13:27:38.024640Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_model = RandomForestClassifier(min_samples_leaf=5,\n",
    "                                     n_estimators=20,\n",
    "                                     max_features=\"log2\",\n",
    "                                     max_depth=4,\n",
    "                                     n_jobs=-1,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:27:40.814434Z",
     "start_time": "2018-11-01T13:27:40.796297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe_tfidf = make_pipeline(tfidf_vectorizer, tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:27:49.870689Z",
     "start_time": "2018-11-01T13:27:41.981063Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_tfidf = fit_ensemble(pipe_tfidf, sss, X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:27:53.989587Z",
     "start_time": "2018-11-01T13:27:52.081543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_tfidf, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.554118Z",
     "start_time": "2018-10-21T17:11:42.077385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.713209Z",
     "start_time": "2018-10-21T17:11:44.557498Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:03.112478Z",
     "start_time": "2018-10-21T17:23:56.079623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 3), max_df=0.8, min_df=0.2, max_features=5000)\n",
    "\n",
    "pipe = make_pipeline(vectorizer, RandomForestClassifier())\n",
    "\n",
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:05.661623Z",
     "start_time": "2018-10-21T17:24:05.156724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:25.557203Z",
     "start_time": "2018-10-21T17:20:25.541996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", TfidfVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000)}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=8,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=10,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.325253Z",
     "start_time": "2018-10-21T17:20:28.199477Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = grid.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.337135Z",
     "start_time": "2018-10-21T17:20:50.330807Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_auc = grid.cv_results_[\"mean_test_score\"].mean()\n",
    "std_auc = grid.cv_results_[\"std_test_score\"].mean()\n",
    "print(f\"Average auc score: {avg_auc:.2f} (+/- {std_auc:.2f})\")\n",
    "# pd.DataFrame.from_dict(grid.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.752909Z",
     "start_time": "2018-10-21T17:20:50.349418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(grid.best_estimator_, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Advanced tokenization and lemmatization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:24:12.630133Z",
     "start_time": "2018-10-24T15:24:11.163316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:24:32.158176Z",
     "start_time": "2018-10-24T15:24:31.110958Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:32:02.077992Z",
     "start_time": "2018-10-24T15:31:59.682984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T14:52:53.664047Z",
     "start_time": "2018-10-24T14:52:53.144816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### SpaCy language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Instructions from SpaCy documentation](https://spacy.io/usage/training#section-textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:44:26.541901Z",
     "start_time": "2018-11-01T11:44:26.503793Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomSpacyClassifier():\n",
    "    \"\"\" Wrapper for spaCy's text classification that enables integration with sklearn.metrics.cross_validate\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._estimator_type = \"classifier\"\n",
    "        \n",
    "        self.nlp = None\n",
    "        self.label = None\n",
    "        self.train_data = None\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return dict()\n",
    "    \n",
    "    def add_textcat(self, label):\n",
    "        self.label = label\n",
    "        if \"textcat\" not in self.nlp.pipe_names:\n",
    "            textcat = self.nlp.create_pipe(\"textcat\")\n",
    "            self.nlp.add_pipe(textcat, last=True)\n",
    "        # otherwise, get it, so we can add labels to it\n",
    "        else:\n",
    "            textcat = self.nlp.get_pipe(\"textcat\")\n",
    "        textcat.add_label(label)\n",
    "    \n",
    "    def fit(self, X, y, n_iter=10, **kwargs):\n",
    "        \n",
    "        self.nlp = spacy.load(\"en\")\n",
    "        self.add_textcat(\"interesting\")\n",
    "        self.train_data = [(e, {\"cats\": {self.label: bool(l)}}) for e, l in zip(X, y)]\n",
    "        \n",
    "        drop_rate = kwargs[\"drop_rate\"]\n",
    "        \n",
    "        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != \"textcat\"]\n",
    "        with self.nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "            optimizer = self.nlp.begin_training()\n",
    "            for i in range(n_iter):\n",
    "                print(f\"EPOCH {i+1}\")\n",
    "                losses = {}\n",
    "                batches = minibatch(self.train_data, size=compounding(4., 16., 1.001))\n",
    "                for batch in batches:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    self.nlp.update(texts, annotations, sgd=optimizer, drop=drop_rate,\n",
    "                               losses=losses)\n",
    "                loss = losses[\"textcat\"]\n",
    "                print(f\"LOSS: {loss}\")\n",
    "                print(\"\")\n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        p1_scores = [np.float64(self.nlp(sample_text).cats[\"interesting\"]) for sample_text in X]\n",
    "        \n",
    "        return np.array([[1. - score, score] for score in p1_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:35:31.121558Z",
     "start_time": "2018-11-01T13:35:29.955588Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:35:39.470011Z",
     "start_time": "2018-11-01T13:35:39.414223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?nlp.update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T11:44:28.992623Z",
     "start_time": "2018-11-01T11:44:28.979279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf_spacy = CustomSpacyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:49:31.983925Z",
     "start_time": "2018-11-01T13:36:42.753687Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_spacy = fit_ensemble(clf_spacy, sss, X_train_text, y_train, n_iter=5, drop_rate=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:53:11.837084Z",
     "start_time": "2018-11-01T13:49:31.992851Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_spacy, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train several custom classifiers and evaluate their performance on the true hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:11.842938Z",
     "start_time": "2018-10-24T13:26:07.503373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_clfs = []\n",
    "\n",
    "for i, split in enumerate(s.split(X_70, y_70)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    \n",
    "    print(\"Training model number  \", i)\n",
    "    print(\"\")\n",
    "    print(\"Training IDs: \", i_train)\n",
    "    print(\"Test IDs: \", i_test)\n",
    "    \n",
    "    clf.fit(X_70[i_train], y_70[i_train], n_iter=5, drop_rate=0.4)\n",
    "    fitted_clf = copy.deepcopy(clf)\n",
    "    test_auc = metrics.roc_auc_score(y_70[i_test], clf.predict_proba(X_70[i_test])[:, 1])\n",
    "    fitted_clfs.append((fitted_clf, test_auc))\n",
    "\n",
    "    print(\"AUC on the test set: \", test_auc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:29.229181Z",
     "start_time": "2018-10-24T13:29:29.222974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = [score for _, score in fitted_clfs]\n",
    "print(\"Mean AUC: \", np.mean(scores))\n",
    "print(\"Std deviation of AUC: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.242453Z",
     "start_time": "2018-10-24T13:29:31.223222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.array([c.predict_proba(X_100)[:, 1] for c, _ in fitted_clfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.257840Z",
     "start_time": "2018-10-24T13:31:33.245011Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"AUC on the hold out set: \", metrics.roc_auc_score(y_100, preds.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:41.728665Z",
     "start_time": "2018-10-21T19:08:15.508664Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_cv = cross_validate(clf, X_text_train, y_train,\n",
    "                            scoring=\"roc_auc\",\n",
    "                            cv=2,\n",
    "                            n_jobs=1,\n",
    "                            return_train_score=False,\n",
    "                            return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:48.231686Z",
     "start_time": "2018-10-21T19:09:48.222714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:28.110965Z",
     "start_time": "2018-10-21T17:25:27.194211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:32.274827Z",
     "start_time": "2018-10-21T17:25:32.269573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\")\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:34.572100Z",
     "start_time": "2018-10-21T17:25:34.562167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "textcat.add_label(\"interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:39.933733Z",
     "start_time": "2018-10-21T17:25:39.926488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = [(example, {\"cats\": {\"interesting\": bool(label)}}) for example, label in zip(X_text_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:26:16.087658Z",
     "start_time": "2018-10-21T17:26:16.080752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dropout = decaying(0.6, 0.2, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(dropout))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=compounding(4., 16., 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(size))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.5))\n",
    "        print(len(next(batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:08.202431Z",
     "start_time": "2018-10-21T17:26:17.696164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.3,\n",
    "                       losses=losses)\n",
    "        loss = losses[\"textcat\"]\n",
    "        print(f\"LOSS: {loss}\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:41.161981Z",
     "start_time": "2018-10-21T17:27:28.334154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_scores = [nlp(sample_text).cats[\"interesting\"] for sample_text in X_text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:38.544596Z",
     "start_time": "2018-10-21T18:36:37.938629Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te = [np.float64(nlp(sample_text).cats[\"interesting\"]) for sample_text in X_text_test[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.001249Z",
     "start_time": "2018-10-21T18:34:35.997389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2 = np.array([[1. - score, score] for score in te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.546165Z",
     "start_time": "2018-10-21T18:34:36.539196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:52.812941Z",
     "start_time": "2018-10-21T18:36:52.802279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.float64(te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:29:17.285373Z",
     "start_time": "2018-10-21T17:29:17.277144Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:30:21.381422Z",
     "start_time": "2018-10-21T17:30:21.260650Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = metrics.precision_recall_curve(y_test, test_scores)\n",
    "\n",
    "step_kwargs = {\"step\": \"post\"}\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where=\"post\")\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision-Recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:14:16.366241Z",
     "start_time": "2018-11-01T22:14:15.361821Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T13:59:40.231997Z",
     "start_time": "2018-11-01T13:59:40.056172Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path.cwd() / \"data\" / \"shared\" / \"train_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T22:21:22.376884Z",
     "start_time": "2018-10-26T22:21:22.236695Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[[\"claps\", \"reading_time\", \"text\"]]\n",
    "y = np.array(data[\"interesting\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3, random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T22:21:33.670266Z",
     "start_time": "2018-10-26T22:21:33.647353Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_fastai = pd.DataFrame({\"label\": y_train, \"text\": X_train[\"text\"]})\n",
    "test_fastai = pd.DataFrame({\"label\": y_test, \"text\": X_test[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T22:25:40.878762Z",
     "start_time": "2018-10-26T22:25:40.864858Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"data\" / \"shared\" / \"fastai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-26T22:25:47.131761Z",
     "start_time": "2018-10-26T22:25:47.064549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_fastai.to_csv(path / \"train.csv\", sep=\",\", index=False, header=False)\n",
    "train_fastai.to_csv(path / \"test.csv\", sep=\",\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_csv(path)\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_csv(path, vocab=data_lm.train_ds.vocab, bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Download pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This did not work, had to do this using curl from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# URLs.download_wt103_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Train language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm, pretrained_fnames=['lstm_wt103', 'itos_wt103'], drop_mult=0.5)\n",
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfreeze and fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Save encoder to use for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.classifier(data_clas, drop_mult=0.5)\n",
    "learn.load_encoder('ft_enc')\n",
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(4, slice(5e-3/2., 5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(2e-3/100, 2e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:17:24.059708Z",
     "start_time": "2018-11-01T22:17:24.046289Z"
    }
   },
   "outputs": [],
   "source": [
    "FittedLearner = namedtuple(\"FittedLearner\", [\n",
    "    \"learner\",\n",
    "    \"train_perf\",\n",
    "    \"valid_perf\"\n",
    "])\n",
    "\n",
    "def fit_ensemble_fastai(path:Path, df:DataFrame, s:StratifiedShuffleSplit, **kwargs):\n",
    "    \"\"\"Fit a model on different subsets of the training set and collect the results\n",
    "    \n",
    "    Arguments:\n",
    "    path - a pathlib Path pointing to the fastai working directory\n",
    "    df - pandas dataframe of labels and text (no header, labels first)\n",
    "    s - an object of class sklearn.model_selection.StratifiedShuffleSplit, i.e. an iterator of random, stratified splits\n",
    "    **kwargs - keyword arguments to pass to the model when calling fit\n",
    "    \n",
    "    Returns:\n",
    "    fitted_clfs - a list of fitted fastai RNNLearner objects\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fitted_clfs = []\n",
    "    epochs = kwargs.get(\"lr\", 1)\n",
    "\n",
    "    for i, split in enumerate(s.split(df, df.iloc[:, 0])):\n",
    "        i_train = split[0]\n",
    "        i_valid = split[1]\n",
    "        \n",
    "        print(\"#######################################\")\n",
    "        print(\"Training model number  \", i+1)\n",
    "        print(\"#######################################\")\n",
    "        print(\"\")\n",
    "        \n",
    "        print(\"Creating language model data bunch\")\n",
    "        print(\"\")\n",
    "        \n",
    "        fname = f\"cvfold{i+1}\"\n",
    "        data_lm = TextLMDataBunch.from_df(path / \"cv\" / fname,\n",
    "                                  train_df=df.iloc[i_train],\n",
    "                                  valid_df=df.iloc[i_valid])\n",
    "        \n",
    "        print(\"Creating classifier data bunch\")\n",
    "        print(\"\")\n",
    "        \n",
    "        data_clas = TextClasDataBunch.from_df(path / \"cv\" / fname,\n",
    "                                      train_df=df.iloc[i_train],\n",
    "                                      valid_df=df.iloc[i_valid],\n",
    "                                      vocab=data_lm.train_ds.vocab,\n",
    "                                      bs=8)\n",
    "        print(\"Finetuning language model\")\n",
    "        print(\"\")\n",
    "        learn = RNNLearner.language_model(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)\n",
    "        learn.fit_one_cycle(epochs, 1e-2)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, 1e-3)\n",
    "        \n",
    "        ename = f\"ft_enc{i+1}\"\n",
    "        learn.save_encoder(ename)\n",
    "        \n",
    "        print(\"Training classifier\")\n",
    "        print(\"\")\n",
    "        learn = RNNLearner.classifier(data_clas, drop_mult=0.5)\n",
    "        learn.load_encoder(ename)\n",
    "        learn.fit_one_cycle(1, 1e-2)\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit_one_cycle(epochs, slice(5e-3/2., 5e-3))\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(1, slice(2e-3/100, 2e-3))\n",
    "        \n",
    "        train_perf = learn.validate(learn.data.train_dl)[1]\n",
    "        valid_perf = learn.recorder.metrics\n",
    "        \n",
    "        fitted_clfs.append(FittedLearner(learn, train_perf, valid_perf))\n",
    "    \n",
    "    return fitted_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:17:25.246682Z",
     "start_time": "2018-11-01T22:17:25.242600Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path.cwd() / \"data\" / \"shared\" / \"train_data_fastai.csv\",\n",
    "                   header=None)\n",
    "path = Path.cwd() / \"data\" / \"shared\" / \"fastai\"\n",
    "s = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:17:56.673556Z",
     "start_time": "2018-11-01T22:17:26.043409Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_learners = fit_ensemble_fastai(path, data, s, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:37:56.767829Z",
     "start_time": "2018-10-21T17:37:56.757286Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\" Simple class holding data and functionality related to evaluating a classifier's performance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, scores):\n",
    "        self.df = pd.DataFrame({\"text\": texts, \"label\": labels, \"score\": scores})\n",
    "        self.group_means = self.df.groupby(by=\"label\").mean()\n",
    "        \n",
    "    def get_scores(self, thresholds=[0.25, 0.5, 0.75]):\n",
    "        if isinstance(thresholds, float):\n",
    "            thresholds = [thresholds]\n",
    "        \n",
    "        tps = [1e-8]*len(thresholds)  # True positives\n",
    "        fps = [1e-8]*len(thresholds)  # False positives\n",
    "        fns = [1e-8]*len(thresholds)  # False negatives\n",
    "        tns = [1e-8]*len(thresholds)  # True negatives\n",
    "        \n",
    "        for i, t in enumerate(thresholds):\n",
    "            for truth, pred in zip(self.df[\"label\"], self.df[\"score\"] > t):\n",
    "                if truth and pred:\n",
    "                    tps[i] += 1.\n",
    "                elif not truth and pred:\n",
    "                    fps[i] += 1.\n",
    "                elif truth and not pred:\n",
    "                    fns[i] += 1.\n",
    "                elif not truth and not pred:\n",
    "                    tns[i] += 1.\n",
    "        \n",
    "        precisions = [tp / (tp + fp) for tp, fp in zip(tps, fps)]\n",
    "        recalls = [tp / (tp + fn) for tp, fn in zip(tps, fns)]\n",
    "        f_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]\n",
    "        accuracies = [(tp + tn) / (tp + fp + fn + tn) for tp, fp, fn, tn in zip(tps, fps, fns, tns)]\n",
    "        \n",
    "        score_df = pd.DataFrame({\"threshold\": thresholds,\n",
    "                                 \"precision\": precisions,\n",
    "                                 \"recall\": recalls,\n",
    "                                 \"f_score\": f_scores,\n",
    "                                 \"accuracy\": accuracies})\n",
    "        \n",
    "        print(score_df)\n",
    "        self.score_df = score_df\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:06.430797Z",
     "start_time": "2018-10-21T17:38:06.417832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator = CustomEvaluator(X_text_test, y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:07.477180Z",
     "start_time": "2018-10-21T17:38:07.465921Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:10.097825Z",
     "start_time": "2018-10-21T17:38:10.081271Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
