{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# file system navigation\n",
    "import os\n",
    "\n",
    "# data transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# nlp\n",
    "import spacy\n",
    "from spacy.pipeline import TextCategorizer\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "\n",
    "# ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# misc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(wd, \"data\", \"processed\", \"train_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>interesting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin Lee</td>\n",
       "      <td>8300</td>\n",
       "      <td>11</td>\n",
       "      <td>https://medium.com/swlh/chatbots-were-the-next...</td>\n",
       "      <td>Chatbots were the next big thing: what happene...</td>\n",
       "      <td>Oh, how the headlines blared:\\nChatbots were T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conor Dewey</td>\n",
       "      <td>1400</td>\n",
       "      <td>7</td>\n",
       "      <td>https://towardsdatascience.com/python-for-data...</td>\n",
       "      <td>Python for Data Science: 8 Concepts You May Ha...</td>\n",
       "      <td>If you’ve ever found yourself looking up the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Koehrsen</td>\n",
       "      <td>2800</td>\n",
       "      <td>11</td>\n",
       "      <td>https://towardsdatascience.com/automated-featu...</td>\n",
       "      <td>Automated Feature Engineering in Python – Towa...</td>\n",
       "      <td>Machine learning is increasingly moving from h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Irhum Shafkat</td>\n",
       "      <td>2000</td>\n",
       "      <td>15</td>\n",
       "      <td>https://towardsdatascience.com/intuitively-und...</td>\n",
       "      <td>Intuitively Understanding Convolutions for Dee...</td>\n",
       "      <td>The advent of powerful and versatile deep lear...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam Drozdov</td>\n",
       "      <td>2300</td>\n",
       "      <td>6</td>\n",
       "      <td>https://uxdesign.cc/an-intro-to-machine-learni...</td>\n",
       "      <td>An intro to Machine Learning for designers – U...</td>\n",
       "      <td>There is an ongoing debate about whether or no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author  claps  reading_time  \\\n",
       "0        Justin Lee   8300            11   \n",
       "1       Conor Dewey   1400             7   \n",
       "2  William Koehrsen   2800            11   \n",
       "3     Irhum Shafkat   2000            15   \n",
       "4       Sam Drozdov   2300             6   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://medium.com/swlh/chatbots-were-the-next...   \n",
       "1  https://towardsdatascience.com/python-for-data...   \n",
       "2  https://towardsdatascience.com/automated-featu...   \n",
       "3  https://towardsdatascience.com/intuitively-und...   \n",
       "4  https://uxdesign.cc/an-intro-to-machine-learni...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Chatbots were the next big thing: what happene...   \n",
       "1  Python for Data Science: 8 Concepts You May Ha...   \n",
       "2  Automated Feature Engineering in Python – Towa...   \n",
       "3  Intuitively Understanding Convolutions for Dee...   \n",
       "4  An intro to Machine Learning for designers – U...   \n",
       "\n",
       "                                                text  interesting  \n",
       "0  Oh, how the headlines blared:\\nChatbots were T...            0  \n",
       "1  If you’ve ever found yourself looking up the s...            0  \n",
       "2  Machine learning is increasingly moving from h...            1  \n",
       "3  The advent of powerful and versatile deep lear...            1  \n",
       "4  There is an ongoing debate about whether or no...            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model using author, claps and reading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base = data[[\"claps\", \"reading_time\", \"interesting\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_base[[\"claps\", \"reading_time\"]]\n",
    "y = data_base[\"interesting\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claps</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>interesting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8300</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1400</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2800</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2300</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   claps  reading_time  interesting\n",
       "0   8300            11            0\n",
       "1   1400             7            0\n",
       "2   2800            11            1\n",
       "3   2000            15            1\n",
       "4   2300             6            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.savefig(os.path.join(wd, \"output\", \"base_classifier.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(wd, \"output\", \"base_classifier.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build text based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"interesting\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Instructions from SpaCy documentation](https://spacy.io/usage/training#section-textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\")\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat.add_label(\"interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = [(example, {\"cats\": {\"interesting\": bool(label)}}) for example, label in zip(X_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = decaying(0.6, 0.2, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(dropout))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=compounding(4., 16., 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(size))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.5))\n",
    "        print(len(next(batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.3,\n",
    "                       losses=losses)\n",
    "        loss = losses[\"textcat\"]\n",
    "        print(f\"LOSS: {loss}\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = [nlp(sample_text).cats[\"interesting\"] for sample_text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator = CustomEvaluator(X_test, y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator.group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_evaluator.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [nlp(sample_text).cats[\"interesting\"] for sample_text in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator = CustomEvaluator(X_train, y_train, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_evaluator.group_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluator.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\" Simple class holding data and functionality related to evaluating the classifiers performance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, scores):\n",
    "        self.df = pd.DataFrame({\"text\": texts, \"label\": labels, \"score\": scores})\n",
    "        self.group_means = self.df.groupby(by=\"label\").mean()\n",
    "        \n",
    "    def get_scores(self, thresholds=[0.25, 0.5, 0.75]):\n",
    "        if isinstance(thresholds, float):\n",
    "            thresholds = [thresholds]\n",
    "        \n",
    "        tps = [1e-8]*len(thresholds)  # True positives\n",
    "        fps = [1e-8]*len(thresholds)  # False positives\n",
    "        fns = [1e-8]*len(thresholds)  # False negatives\n",
    "        tns = [1e-8]*len(thresholds)  # True negatives\n",
    "        \n",
    "        for i, t in enumerate(thresholds):\n",
    "            for truth, pred in zip(self.df[\"label\"], self.df[\"score\"] > t):\n",
    "                if truth and pred:\n",
    "                    tps[i] += 1.\n",
    "                elif not truth and pred:\n",
    "                    fps[i] += 1.\n",
    "                elif truth and not pred:\n",
    "                    fns[i] += 1.\n",
    "                elif not truth and not pred:\n",
    "                    tns[i] += 1.\n",
    "        \n",
    "        precisions = [tp / (tp + fp) for tp, fp in zip(tps, fps)]\n",
    "        recalls = [tp / (tp + fn) for tp, fn in zip(tps, fns)]\n",
    "        f_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]\n",
    "        accuracies = [(tp + tn) / (tp + fp + fn + tn) for tp, fp, fn, tn in zip(tps, fps, fns, tns)]\n",
    "        \n",
    "        score_df = pd.DataFrame({\"threshold\": thresholds,\n",
    "                                 \"precision\": precisions,\n",
    "                                 \"recall\": recalls,\n",
    "                                 \"f_score\": f_scores,\n",
    "                                 \"accuracy\": accuracies})\n",
    "        \n",
    "        print(score_df)\n",
    "        self.score_df = score_df\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:medium-classifier]",
   "language": "python",
   "name": "conda-env-medium-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
