{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General steps:\n",
    "\n",
    "- Split into train and test set (random and stratified, using sklearn train_test_split)\n",
    "- Learn transformations and word -> token mapping on train set \n",
    "- Train model on train set (potentially train severals model on different subsets and choose the best one / ensemble their predictions, in the latter case calculate out of bag score as well)\n",
    "- Calculate performance on train set (custom performance metric - choose threshold to get precision to >95% and evaluate recall based on that)\n",
    "- Apply transformations on test set, make predictions and evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.354620Z",
     "start_time": "2018-11-25T17:52:19.764270Z"
    }
   },
   "outputs": [],
   "source": [
    "# debugging\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# file system navigation\n",
    "from pathlib import Path\n",
    "\n",
    "# data transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ml algorithms and evaluation metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "# sklearn specifics\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# nlp\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.pipeline import TextCategorizer\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "\n",
    "# misc\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.371879Z",
     "start_time": "2018-11-25T17:52:23.361000Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_html(df:pd.DataFrame, name:str) -> None:\n",
    "    html = (df\n",
    "            .to_html()\n",
    "            .replace('<tr>', '<tr align=\"center\">')\n",
    "            .replace('<tr style=\"text-align: right;\">', '<tr style=\"text-align: center;\">')\n",
    "            .replace('border=\"1\"', 'border=\"2\"')\n",
    "            .replace('<th>', '<th><center>'))\n",
    "    with open(Path.cwd() / \"reports\" / \"images\" / f\"{name}.html\", \"w\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.494433Z",
     "start_time": "2018-11-25T17:52:23.379663Z"
    },
    "code_folding": [
     8,
     29
    ]
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_precision:float=0.95, pos_label:int=1):\n",
    "        self.target_precision = target_precision\n",
    "        self.pos_label = pos_label\n",
    "        \n",
    "    def score(self, y_true:ndarray, probas_pred:ndarray):\n",
    "        prs, rcs, ths = metrics.precision_recall_curve(y_true, probas_pred, pos_label=self.pos_label)\n",
    "    \n",
    "        auc = metrics.roc_auc_score(y_true, probas_pred)\n",
    "        print(f\"AUC SCORE: {auc:.2f}\")\n",
    "        results = pd.DataFrame({\"precision\": prs[:-1], \"recall\": rcs[:-1], \"threshold\": ths})\\\n",
    "                    .sort_values(by=[\"precision\", \"recall\"], ascending=[False, False])\n",
    "        if np.max(results.precision) > self.target_precision:\n",
    "            print(results[results.precision >= self.target_precision])\n",
    "        else:\n",
    "            print(results.head(3))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.608398Z",
     "start_time": "2018-11-25T17:52:23.500747Z"
    }
   },
   "outputs": [],
   "source": [
    "ScoredClf = namedtuple(\"ScoredClf\", [\n",
    "    \"clf\",\n",
    "    \"train_auc\",\n",
    "    \"oob_auc\"\n",
    "])\n",
    "\n",
    "def fit_ensemble(m, s:StratifiedShuffleSplit, X:ndarray, y:ndarray, **kwargs) -> namedtuple:\n",
    "    \"\"\"Fit a model on different subsets of the training set and collect the results\n",
    "    \n",
    "    Arguments:\n",
    "    m - a model object implementing `fit` and `predict_proba`\n",
    "    s - an object of class sklearn.model_selection.StratifiedShuffleSplit, i.e. an iterator of random, stratified splits\n",
    "    X - numpy array of training texts\n",
    "    y - numpy array of training labels\n",
    "    **kwargs - keyword arguments to pass to the model when calling fit\n",
    "    \n",
    "    Returns:\n",
    "    fitted_clfs - a list of named tuples collecting the scored classifiers as well as their training and out of bag AUCs\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fitted_clfs = []\n",
    "\n",
    "    for i, split in enumerate(s.split(X, y)):\n",
    "        i_train = split[0]\n",
    "        i_test = split[1]\n",
    "        \n",
    "        print(\"#######################################\")\n",
    "        print(\"Training model number  \", i+1)\n",
    "        print(\"#######################################\")\n",
    "        print(\"\")\n",
    "\n",
    "        m.fit(X[i_train], y[i_train], **kwargs)\n",
    "        fitted_clf = copy.deepcopy(m)\n",
    "        \n",
    "        p1_train = fitted_clf.predict_proba(X[i_train])[:, 1]\n",
    "        p1_oob = fitted_clf.predict_proba(X[i_test])[:, 1]\n",
    "        \n",
    "        train_auc = metrics.roc_auc_score(y[i_train], p1_train)\n",
    "        oob_auc = metrics.roc_auc_score(y[i_test], p1_oob)\n",
    "        fitted_clfs.append(ScoredClf(fitted_clf, train_auc, oob_auc))\n",
    "        \n",
    "        print(\"PERFORMANCE ON TRAIN\")\n",
    "        print(\"\")\n",
    "        evaluator.score(y[i_train], p1_train)\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"OOB PERFORMANCE\")\n",
    "        print(\"\")\n",
    "        evaluator.score(y[i_test], p1_oob)\n",
    "        \n",
    "        print(\"\")\n",
    "    \n",
    "    return fitted_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.740054Z",
     "start_time": "2018-11-25T17:52:23.619771Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_ensemble(fitted:List, eval:CustomEvaluator, X_test:ndarray):\n",
    "    \"\"\"Evaluate the performance of a set of classifiers trained on different subsets of the training set\n",
    "    \n",
    "    Arguments:\n",
    "    fitted - list of named tuples containing fitted models as well as their train and out of bag AUC\n",
    "    eval - object of class CustomEvaluator used to evaluate the performance on the hold out set\n",
    "    X_test - numpy array of the texts for the hold out set for final evaluation\n",
    "    \n",
    "    Return:\n",
    "    None - the function is just useful for its side effects\n",
    "    \"\"\"\n",
    "    train_scores = [m.train_auc for m in fitted]\n",
    "    oob_scores = [m.oob_auc for m in fitted]\n",
    "    preds_test = np.array([m.clf.predict_proba(X_test)[:, 1] for m in fitted])\n",
    "\n",
    "    print(f\"Mean Train AUC: {np.mean(train_scores):.2f} (+/- {np.std(train_scores):.2f})\")\n",
    "    print(f\"Mean OOB AUC: {np.mean(oob_scores):.2f} (+/- {np.std(oob_scores):.2f})\")\n",
    "    print(\"\")\n",
    "    print(\"Performance on hold out set:\")\n",
    "    eval.score(y_test, preds_test.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:23.851808Z",
     "start_time": "2018-11-25T17:52:23.749332Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_ensemble(fitted:List, eval:CustomEvaluator, X_test:ndarray):\n",
    "    \"\"\"Evaluate the performance of a set of classifiers trained on different subsets of the training set\n",
    "    \n",
    "    Arguments:\n",
    "    fitted - list of named tuples containing fitted models as well as their train and out of bag AUC\n",
    "    eval - object of class CustomEvaluator used to evaluate the performance on the hold out set\n",
    "    X_test - numpy array of the texts for the hold out set for final evaluation\n",
    "    \n",
    "    Return:\n",
    "    None - the function is just useful for its side effects\n",
    "    \"\"\"\n",
    "    \n",
    "    if hasattr(fitted[0], \"clf\"):\n",
    "        train_scores = [m.train_auc for m in fitted]\n",
    "        oob_scores = [m.oob_auc for m in fitted]\n",
    "        preds_test = np.array([m.clf.predict_proba(X_test)[:, 1] for m in fitted])\n",
    "        print(f\"Mean Train AUC: {np.mean(train_scores):.2f} (+/- {np.std(train_scores):.2f})\")\n",
    "        print(f\"Mean OOB AUC: {np.mean(oob_scores):.2f} (+/- {np.std(oob_scores):.2f})\")\n",
    "        print(\"\")\n",
    "        \n",
    "    else: preds_test = np.array([m.predict_proba(X_test)[:, 1] for m in fitted])\n",
    "    print(\"Performance on hold out set:\")\n",
    "    eval.score(y_test, preds_test.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_scores(model, X, y, n_cv=10):\n",
    "    precision_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"precision\")\n",
    "    recall_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"recall\")\n",
    "    print(f\"Average precision score for {n_cv} splits: {precision_scores.mean():.2f} (+/- {precision_scores.std():.2f})\")\n",
    "    print(f\"Average recall score for {n_cv} splits: {recall_scores.mean():.2f} (+/- {recall_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:23:53.465807Z",
     "start_time": "2018-10-21T16:23:53.459929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_score_auc(model, X, y, n_cv=10):\n",
    "    auc_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"roc_auc\")\n",
    "    print(f\"Average auc score for {n_cv} splits: {auc_scores.mean():.2f} (+/- {auc_scores.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:42.909551Z",
     "start_time": "2018-10-23T16:13:42.903097Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_auc(model, X, y, n_cv=10):\n",
    "    auc_cv = cross_validate(model, X, y,\n",
    "                                scoring=\"roc_auc\",\n",
    "                                cv=n_cv,\n",
    "                                n_jobs=-1,\n",
    "                                return_train_score=False,\n",
    "                                return_estimator=True)\n",
    "    auc_scores = auc_cv[\"test_score\"]\n",
    "    mean_auc = auc_scores.mean()\n",
    "    representative_estimator = auc_cv[\"estimator\"][np.argmin([np.abs(score - mean_auc) for score in auc_scores])]\n",
    "    print(f\"Average auc score for {n_cv} splits: {mean_auc:.2f} (+/- {auc_scores.std():.2f})\")\n",
    "    \n",
    "    return representative_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:49:35.059330Z",
     "start_time": "2018-10-21T16:49:35.049853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(model, X, y):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "    step_kwargs = {\"step\": \"post\"}\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where=\"post\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:29:36.517400Z",
     "start_time": "2018-11-25T17:29:36.477797Z"
    }
   },
   "outputs": [],
   "source": [
    "google_trends_ml = pd.read_csv(Path.cwd() / \"data\" / \"trends-ml.csv\",\n",
    "                               skiprows=3,\n",
    "                               header=None,\n",
    "                               names=[\"date\", \"interest\"],\n",
    "                               parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:29:37.623420Z",
     "start_time": "2018-11-25T17:29:37.580269Z"
    }
   },
   "outputs": [],
   "source": [
    "google_trends_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:01.287424Z",
     "start_time": "2018-11-25T17:49:00.879473Z"
    }
   },
   "outputs": [],
   "source": [
    "interest_plot = google_trends_ml.plot(x=\"date\",\n",
    "                      y=\"interest\",\n",
    "                      legend=False)\n",
    "interest_plot.set_xlabel(\"Date\")\n",
    "interest_plot.set_ylabel(\"Relative interest\")\n",
    "interest_plot;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:49:03.023682Z",
     "start_time": "2018-11-25T17:49:02.825958Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = interest_plot.get_figure()\n",
    "fig.savefig(Path.cwd() / \"reports\" / \"images\" / \"interest-in-ml.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data and make split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:33.661729Z",
     "start_time": "2018-11-25T17:52:33.315630Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path.cwd() / \"data\" / \"processed\" / \"train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:33.862346Z",
     "start_time": "2018-11-25T17:52:33.842086Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:35.700254Z",
     "start_time": "2018-11-25T17:52:35.661140Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data[[\"claps\", \"reading_time\", \"text\"]]\n",
    "y = np.array(data[\"interesting\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3, random_state=123,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:36.016205Z",
     "start_time": "2018-11-25T17:52:35.997283Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator = CustomEvaluator(target_precision=0.8)\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=6, test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:39.077184Z",
     "start_time": "2018-11-25T17:52:39.006859Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:40.135476Z",
     "start_time": "2018-11-25T17:52:40.014672Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_numeric = (data[[\"claps\", \"reading_time\"]]\n",
    "                   .describe()\n",
    "                   .round(2))\n",
    "summary_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:19:18.857020Z",
     "start_time": "2018-11-25T17:19:18.823752Z"
    }
   },
   "outputs": [],
   "source": [
    "make_html(summary_numeric, \"summary_numeric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:44.200516Z",
     "start_time": "2018-11-25T17:52:44.096004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_object = data[[\"author\", \"title\", \"text\"]].describe()\n",
    "summary_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:19:22.301890Z",
     "start_time": "2018-11-25T17:19:22.251531Z"
    }
   },
   "outputs": [],
   "source": [
    "make_html(summary_object, \"summary_object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:52:46.405683Z",
     "start_time": "2018-11-25T17:52:46.364230Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"interesting\"].value_counts() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:58:25.509691Z",
     "start_time": "2018-11-25T17:58:25.487914Z"
    }
   },
   "outputs": [],
   "source": [
    "data_base = data[[\"claps\", \"reading_time\", \"interesting\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T17:58:53.443251Z",
     "start_time": "2018-11-25T17:58:52.991654Z"
    }
   },
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "plt.savefig(Path.cwd() / \"reports\" / \"images\" / \"base_classifier.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:40:29.220817Z",
     "start_time": "2018-11-25T13:40:29.212467Z"
    }
   },
   "outputs": [],
   "source": [
    "data_base = data[[\"claps\", \"reading_time\", \"interesting\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize data distribution for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(wd, \"output\", \"base_classifier.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline classficiation model using author, claps and reading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:40:35.531009Z",
     "start_time": "2018-11-25T13:40:35.521753Z"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = [\"claps\", \"reading_time\"]\n",
    "X_train_num, X_test_num = np.array(X_train[num_cols]), np.array(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:40:39.900773Z",
     "start_time": "2018-11-25T13:40:39.896608Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:40:40.895485Z",
     "start_time": "2018-11-25T13:40:40.713268Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted = fit_ensemble(rf, sss, X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:40:49.733991Z",
     "start_time": "2018-11-25T13:40:49.703033Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted, evaluator, X_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:56.804070Z",
     "start_time": "2018-10-23T16:13:53.798814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_model = get_cv_auc(RandomForestClassifier(), X_num, y, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:21:28.607292Z",
     "start_time": "2018-10-23T16:21:28.601934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = model_selection.StratifiedShuffleSplit(n_splits=4, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:32:32.143735Z",
     "start_time": "2018-10-23T16:32:32.073254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, split in enumerate(s.split(X_num, y_num)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    print(\"Training model number  \", i)\n",
    "    rf_model.fit(X_num.iloc[i_train, :], y_num[i_train])\n",
    "    print(\"AUC on the test set:\")\n",
    "    print(metrics.roc_auc_score(y_num[i_test], rf_model.predict_proba(X_num.iloc[i_test, :])[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T09:58:38.672284Z",
     "start_time": "2018-11-25T09:58:38.656865Z"
    }
   },
   "outputs": [],
   "source": [
    "text_col = \"text\"\n",
    "X_train_text, X_test_text = np.array(X_train[text_col]), np.array(X_test[text_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T12:45:20.557778Z",
     "start_time": "2018-10-24T12:45:20.552611Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = data[\"text\"]\n",
    "y = data[\"interesting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create true hold out set to simulate future articles coming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:20:47.213764Z",
     "start_time": "2018-10-24T13:20:47.208360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_text[0:70]\n",
    "y_70 = y[0:70]\n",
    "\n",
    "X_100 = X_text[70:]\n",
    "y_100 = y[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:24:47.508398Z",
     "start_time": "2018-10-24T13:24:47.496691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_70.reset_index().drop(\"index\", axis=1)[\"text\"]\n",
    "X_100 = X_100.reset_index().drop(\"index\", axis=1)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:25:34.020042Z",
     "start_time": "2018-10-24T13:25:34.009723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_70 = y_70.reset_index().drop(\"index\", axis=1)[\"interesting\"]\n",
    "y_100 = y_100.reset_index().drop(\"index\", axis=1)[\"interesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T17:16:28.204341Z",
     "start_time": "2018-10-23T17:16:28.198673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text,\n",
    "                                                              y,\n",
    "                                                              test_size=0.3,\n",
    "                                                              random_state=42,\n",
    "                                                              stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T09:58:44.089263Z",
     "start_time": "2018-11-25T09:58:44.074875Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T09:58:45.036962Z",
     "start_time": "2018-11-25T09:58:45.020309Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_countvec = make_pipeline(count_vectorizer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T09:58:52.630583Z",
     "start_time": "2018-11-25T09:58:47.779877Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_countvec = fit_ensemble(pipe_countvec, sss, X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T09:59:08.411292Z",
     "start_time": "2018-11-25T09:59:07.658046Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_countvec, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:58.877105Z",
     "start_time": "2018-10-21T17:10:56.454940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:59.048427Z",
     "start_time": "2018-10-21T17:10:58.880179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Some optimization (preprocessing, feature selection, model tuning) using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:22:05.250501Z",
     "start_time": "2018-11-25T13:22:05.227930Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", CountVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000),\n",
    "          \"rf__n_estimators\": randint(low=10, high=40),\n",
    "          \"rf__max_depth\": randint(low=2, high=8),\n",
    "          \"rf__min_samples_leaf\": randint(low=1, high=10),\n",
    "          \"rf__max_features\": [0.5, \"sqrt\", \"auto\"]}\n",
    "\n",
    "grid_1 = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)\n",
    "\n",
    "grid_2 = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)\n",
    "\n",
    "grid_3 = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:23:05.868556Z",
     "start_time": "2018-11-25T13:22:05.994641Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = grid_1.fit(X_train_text, y_train)\n",
    "_ = grid_2.fit(X_train_text, y_train)\n",
    "_ = grid_3.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:24:02.201395Z",
     "start_time": "2018-11-25T13:23:59.761205Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator_1 = grid_1.best_estimator_.fit(X_train_text, y_train)\n",
    "estimator_2 = grid_2.best_estimator_.fit(X_train_text, y_train)\n",
    "estimator_3 = grid_3.best_estimator_.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:26:11.606847Z",
     "start_time": "2018-11-25T13:26:11.521745Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([estimator_1], evaluator, X_test_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:26:36.517209Z",
     "start_time": "2018-11-25T13:26:36.389830Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([estimator_2], evaluator, X_test_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:26:51.183592Z",
     "start_time": "2018-11-25T13:26:51.074715Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([estimator_3], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:19:49.967677Z",
     "start_time": "2018-11-25T10:19:49.948803Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_model = RandomForestClassifier(min_samples_leaf=5,\n",
    "                                     n_estimators=20,\n",
    "                                     max_features=\"log2\",\n",
    "                                     max_depth=4,\n",
    "                                     n_jobs=-1,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:42:36.676895Z",
     "start_time": "2018-11-25T13:42:36.669696Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe_tfidf = make_pipeline(tfidf_vectorizer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:42:48.723840Z",
     "start_time": "2018-11-25T13:42:46.420724Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_tfidf = fit_ensemble(pipe_tfidf, sss, X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:42:58.891076Z",
     "start_time": "2018-11-25T13:42:58.548277Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_tfidf, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:19:59.835810Z",
     "start_time": "2018-11-25T10:19:52.510291Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_tfidf = fit_ensemble(pipe_tfidf, sss, X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:20:02.757926Z",
     "start_time": "2018-11-25T10:20:01.044337Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_tfidf, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.554118Z",
     "start_time": "2018-10-21T17:11:42.077385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.713209Z",
     "start_time": "2018-10-21T17:11:44.557498Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:03.112478Z",
     "start_time": "2018-10-21T17:23:56.079623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 3), max_df=0.8, min_df=0.2, max_features=5000)\n",
    "\n",
    "pipe = make_pipeline(vectorizer, RandomForestClassifier())\n",
    "\n",
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:05.661623Z",
     "start_time": "2018-10-21T17:24:05.156724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:33:18.853667Z",
     "start_time": "2018-11-25T13:33:18.832921Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", TfidfVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000),\n",
    "          \"rf__n_estimators\": randint(low=10, high=40),\n",
    "          \"rf__max_depth\": randint(low=2, high=8),\n",
    "          \"rf__min_samples_leaf\": randint(low=1, high=10),\n",
    "          \"rf__max_features\": [0.5, \"sqrt\", \"auto\"]}\n",
    "\n",
    "grid_1_tfidf = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)\n",
    "\n",
    "grid_2_tfidf = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)\n",
    "\n",
    "grid_3_tfidf = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=10,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=5,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:34:15.421588Z",
     "start_time": "2018-11-25T13:33:19.499346Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = grid_1_tfidf.fit(X_train_text, y_train)\n",
    "_ = grid_2_tfidf.fit(X_train_text, y_train)\n",
    "_ = grid_3_tfidf.fit(X_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:35:20.510439Z",
     "start_time": "2018-11-25T13:35:20.425976Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([grid_1_tfidf.best_estimator_], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:35:24.947577Z",
     "start_time": "2018-11-25T13:35:24.825050Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([grid_2_tfidf.best_estimator_], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:35:26.498774Z",
     "start_time": "2018-11-25T13:35:26.403392Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([grid_3_tfidf.best_estimator_], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:35:34.866525Z",
     "start_time": "2018-11-25T13:35:34.638299Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble([grid_1_tfidf.best_estimator_, grid_2_tfidf.best_estimator_, grid_3_tfidf.best_estimator_], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SpaCy language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Instructions from SpaCy documentation](https://spacy.io/usage/training#section-textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:20:47.301752Z",
     "start_time": "2018-11-25T10:20:47.262793Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomSpacyClassifier():\n",
    "    \"\"\" Wrapper for spaCy's text classification that enables integration with sklearn.metrics.cross_validate\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._estimator_type = \"classifier\"\n",
    "        \n",
    "        self.nlp = None\n",
    "        self.label = None\n",
    "        self.train_data = None\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return dict()\n",
    "    \n",
    "    def add_textcat(self, label):\n",
    "        self.label = label\n",
    "        if \"textcat\" not in self.nlp.pipe_names:\n",
    "            textcat = self.nlp.create_pipe(\"textcat\")\n",
    "            self.nlp.add_pipe(textcat, last=True)\n",
    "        # otherwise, get it, so we can add labels to it\n",
    "        else:\n",
    "            textcat = self.nlp.get_pipe(\"textcat\")\n",
    "        textcat.add_label(label)\n",
    "    \n",
    "    def fit(self, X, y, n_iter=10, **kwargs):\n",
    "        \n",
    "        self.nlp = spacy.load(\"en\")\n",
    "        self.add_textcat(\"interesting\")\n",
    "        self.train_data = [(e, {\"cats\": {self.label: bool(l)}}) for e, l in zip(X, y)]\n",
    "        \n",
    "        drop_rate = kwargs[\"drop_rate\"]\n",
    "        \n",
    "        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != \"textcat\"]\n",
    "        with self.nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "            optimizer = self.nlp.begin_training()\n",
    "            for i in range(n_iter):\n",
    "                print(f\"EPOCH {i+1}\")\n",
    "                losses = {}\n",
    "                batches = minibatch(self.train_data, size=compounding(4., 16., 1.001))\n",
    "                for batch in batches:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    self.nlp.update(texts, annotations, sgd=optimizer, drop=drop_rate,\n",
    "                               losses=losses)\n",
    "                loss = losses[\"textcat\"]\n",
    "                print(f\"LOSS: {loss}\")\n",
    "                print(\"\")\n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        p1_scores = [np.float64(self.nlp(sample_text).cats[\"interesting\"]) for sample_text in X]\n",
    "        \n",
    "        return np.array([[1. - score, score] for score in p1_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:20:51.681830Z",
     "start_time": "2018-11-25T10:20:49.815290Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:20:53.556415Z",
     "start_time": "2018-11-25T10:20:53.535100Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_spacy = CustomSpacyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:34:31.937623Z",
     "start_time": "2018-11-25T10:20:56.981637Z"
    }
   },
   "outputs": [],
   "source": [
    "fitted_spacy = fit_ensemble(clf_spacy, sss, X_train_text, y_train, n_iter=5, drop_rate=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T10:37:31.478364Z",
     "start_time": "2018-11-25T10:34:31.944130Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_ensemble(fitted_spacy, evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-25T13:37:33.399044Z",
     "start_time": "2018-11-25T13:35:46.324635Z"
    }
   },
   "outputs": [],
   "source": [
    "for m in fitted_spacy:\n",
    "    evaluate_ensemble([m], evaluator, X_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train several custom classifiers and evaluate their performance on the true hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:11.842938Z",
     "start_time": "2018-10-24T13:26:07.503373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_clfs = []\n",
    "\n",
    "for i, split in enumerate(s.split(X_70, y_70)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    \n",
    "    print(\"Training model number  \", i)\n",
    "    print(\"\")\n",
    "    print(\"Training IDs: \", i_train)\n",
    "    print(\"Test IDs: \", i_test)\n",
    "    \n",
    "    clf.fit(X_70[i_train], y_70[i_train], n_iter=5, drop_rate=0.4)\n",
    "    fitted_clf = copy.deepcopy(clf)\n",
    "    test_auc = metrics.roc_auc_score(y_70[i_test], clf.predict_proba(X_70[i_test])[:, 1])\n",
    "    fitted_clfs.append((fitted_clf, test_auc))\n",
    "\n",
    "    print(\"AUC on the test set: \", test_auc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:29.229181Z",
     "start_time": "2018-10-24T13:29:29.222974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = [score for _, score in fitted_clfs]\n",
    "print(\"Mean AUC: \", np.mean(scores))\n",
    "print(\"Std deviation of AUC: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.242453Z",
     "start_time": "2018-10-24T13:29:31.223222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.array([c.predict_proba(X_100)[:, 1] for c, _ in fitted_clfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.257840Z",
     "start_time": "2018-10-24T13:31:33.245011Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"AUC on the hold out set: \", metrics.roc_auc_score(y_100, preds.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:41.728665Z",
     "start_time": "2018-10-21T19:08:15.508664Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_cv = cross_validate(clf, X_text_train, y_train,\n",
    "                            scoring=\"roc_auc\",\n",
    "                            cv=2,\n",
    "                            n_jobs=1,\n",
    "                            return_train_score=False,\n",
    "                            return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:48.231686Z",
     "start_time": "2018-10-21T19:09:48.222714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:28.110965Z",
     "start_time": "2018-10-21T17:25:27.194211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:32.274827Z",
     "start_time": "2018-10-21T17:25:32.269573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\")\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:34.572100Z",
     "start_time": "2018-10-21T17:25:34.562167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "textcat.add_label(\"interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:39.933733Z",
     "start_time": "2018-10-21T17:25:39.926488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = [(example, {\"cats\": {\"interesting\": bool(label)}}) for example, label in zip(X_text_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:26:16.087658Z",
     "start_time": "2018-10-21T17:26:16.080752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dropout = decaying(0.6, 0.2, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(dropout))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=compounding(4., 16., 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(size))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.5))\n",
    "        print(len(next(batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:08.202431Z",
     "start_time": "2018-10-21T17:26:17.696164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.3,\n",
    "                       losses=losses)\n",
    "        loss = losses[\"textcat\"]\n",
    "        print(f\"LOSS: {loss}\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:41.161981Z",
     "start_time": "2018-10-21T17:27:28.334154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_scores = [nlp(sample_text).cats[\"interesting\"] for sample_text in X_text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:38.544596Z",
     "start_time": "2018-10-21T18:36:37.938629Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te = [np.float64(nlp(sample_text).cats[\"interesting\"]) for sample_text in X_text_test[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.001249Z",
     "start_time": "2018-10-21T18:34:35.997389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2 = np.array([[1. - score, score] for score in te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.546165Z",
     "start_time": "2018-10-21T18:34:36.539196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:52.812941Z",
     "start_time": "2018-10-21T18:36:52.802279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.float64(te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:29:17.285373Z",
     "start_time": "2018-10-21T17:29:17.277144Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:30:21.381422Z",
     "start_time": "2018-10-21T17:30:21.260650Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = metrics.precision_recall_curve(y_test, test_scores)\n",
    "\n",
    "step_kwargs = {\"step\": \"post\"}\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where=\"post\")\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision-Recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:18:13.636961Z",
     "start_time": "2018-11-18T14:18:08.826478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from collections import namedtuple\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:26:39.926099Z",
     "start_time": "2018-11-18T14:26:39.882742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path.cwd() / \"data\" / \"shared\" / \"train_data_fastai.csv\",\n",
    "                   header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:26:41.580040Z",
     "start_time": "2018-11-18T14:26:41.565399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Train and evaluate using custom metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.columns = [\"label\", \"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:24:13.458848Z",
     "start_time": "2018-11-18T14:24:13.454103Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PATH = Path.cwd() / \"data\" / \"shared\" / \"fastai\"\n",
    "os.makedirs(PATH / \"exp\", exist_ok=True)\n",
    "EXP_PATH = PATH / \"exp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Train and Evaluate the Language Model (Metric : Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:26:59.235384Z",
     "start_time": "2018-11-18T14:26:52.772832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(df=data, path=EXP_PATH, cols=\"text\")\n",
    "             .random_split_by_pct()\n",
    "             .label_for_lm()\n",
    "             .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T14:29:03.974583Z",
     "start_time": "2018-11-18T14:28:05.094071Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-18T14:29:21.347Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(2, 5e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"fit_head\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load(\"fit_head\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(3, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save_encoder(\"fine_tuned_enc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Train and Evaluate the Classifier (Metric = F_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_clf = (TextList.from_df(df=data, path=EXP_PATH, cols=[\"text\"], vocab=data_lm.vocab)\n",
    "               .random_split_by_pct()\n",
    "               .label_from_df(cols=\"label\")\n",
    "               .databunch(bs=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "My initial objective was to achieve `precision = 0.95` and `recall = 0.75`. As `0.75 / 0.95` is approx. `0.8`, I will use the fbeta score with `beta = 0.8` to evaluate my classifier. Let's calculate the benchmark first:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def f_beta(beta, pr, rc):\n",
    "    beta2 = beta**2\n",
    "    return (1+beta2) * pr*rc / (beta2*pr + rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f_beta(0.8, 0.95, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class FBetaBinary(Callback):\n",
    "    \"Computes the f_beta between preds and targets for binary classification\"\n",
    "\n",
    "    def __init__(self, beta=1, eps=1e-9, sigmoid=True, thresh=0.5):      \n",
    "        self.beta2 = beta**2\n",
    "        self.eps = eps\n",
    "        self.sigmoid = sigmoid\n",
    "        self.thresh = thresh\n",
    "    \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        self.TP = 0\n",
    "        self.total_y_pred = 0   \n",
    "        self.total_y_true = 0\n",
    "    \n",
    "    def on_batch_end(self, last_output, last_target, **kwargs):\n",
    "        y_pred = last_output\n",
    "        y_pred = y_pred.softmax(dim=1)\n",
    "        y_pred = (y_pred[:, 1]>self.thresh).float()\n",
    "        y_true = last_target.float()\n",
    "        \n",
    "        self.TP += ((y_pred==1) * (y_true==1)).float().sum()\n",
    "        self.total_y_pred += (y_pred==1).float().sum()\n",
    "        self.total_y_true += (y_true==1).float().sum()\n",
    "    \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        prec = self.TP / (self.total_y_pred+self.eps)\n",
    "        rec = self.TP / (self.total_y_true+self.eps)\n",
    "        res = (prec*rec) / (prec*self.beta2+rec+self.eps) * (1+self.beta2)        \n",
    "        self.metric = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for t in np.arange(0.1, 0.4, 0.05):\n",
    "    metrics.append(FBetaBinary(beta=0.8, thresh=t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_clf, drop_mult=0.5)\n",
    "learn.load_encoder(\"fine_tuned_enc\")\n",
    "learn.metrics = metrics\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load(\"first\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load(\"second\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load(\"three\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(5e-4/(2.6**4),5e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"data\" / \"shared\" / \"fastai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = StratifiedShuffleSplit(n_splits=3, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i_train, i_valid = next(s.split(data, data.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(i_train), len(i_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Create data bunches directly from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(path / \"cv\" / \"manual_04\",\n",
    "                          train_df=data.iloc[i_train],\n",
    "                          valid_df=data.iloc[i_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path / \"cv\" / \"manual_04\",\n",
    "                                      train_df=data.iloc[i_train],\n",
    "                                      valid_df=data.iloc[i_valid],\n",
    "                                      vocab=data_lm.train_ds.vocab,\n",
    "                                      bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Create data bunches from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.makedirs(path / \"cv\" / \"manual_csv\", exist_ok=True)\n",
    "data.iloc[i_train].to_csv(path / \"cv\" / \"manual_csv\" / \"train.csv\", header=None, index=False)\n",
    "data.iloc[i_valid].to_csv(path / \"cv\" / \"manual_csv\" / \"valid.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_csv(path / \"cv\" / \"manual_csv\")\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_csv(path / \"cv\" / \"manual_csv\", vocab=data_lm.train_ds.vocab, bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Do everything with default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)\n",
    "learn.fit_one_cycle(epochs, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(epochs, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save_encoder(\"ft_enc_manual_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.classifier(data_clas, drop_mult=0.5)\n",
    "learn.load_encoder(\"ft_enc_manual_csv\")\n",
    "learn.fit_one_cycle(epochs, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(epochs, slice(5e-3/2., 5e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(epochs, slice(2e-3/100, 2e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Train language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load pretrained model and train for a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.language_model(data_lm, pretrained_model=URLs.WT103, drop_mult=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run learning rate finder to determine optimal lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfreeze and fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, max_lr=slice(5e-3,5e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Save encoder to use for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save_encoder(\"ft_enc_manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Initialize the classifier and load pretrained language model as encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = RNNLearner.classifier(data_clas, drop_mult=0.7)\n",
    "learn.load_encoder(\"ft_enc_manual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train the classifier for a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Only train the last two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(4, slice(1e-3, 1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(2e-3/100, 2e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:17:24.059708Z",
     "start_time": "2018-11-01T22:17:24.046289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FittedLearner = namedtuple(\"FittedLearner\", [\n",
    "    \"learner\",\n",
    "    \"train_perf\",\n",
    "    \"valid_perf\"\n",
    "])\n",
    "\n",
    "def fit_ensemble_fastai(path:Path, df:DataFrame, s:StratifiedShuffleSplit, **kwargs):\n",
    "    \"\"\"Fit a model on different subsets of the training set and collect the results\n",
    "    \n",
    "    Arguments:\n",
    "    path - a pathlib Path pointing to the fastai working directory\n",
    "    df - pandas dataframe of labels and text (no header, labels first)\n",
    "    s - an object of class sklearn.model_selection.StratifiedShuffleSplit, i.e. an iterator of random, stratified splits\n",
    "    **kwargs - keyword arguments to pass to the model when calling fit\n",
    "    \n",
    "    Returns:\n",
    "    fitted_clfs - a list of fitted fastai RNNLearner objects\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    fitted_clfs = []\n",
    "    epochs = kwargs.get(\"epochs\", 1)\n",
    "\n",
    "    for i, split in enumerate(s.split(df, df.iloc[:, 0])):\n",
    "        i_train = split[0]\n",
    "        i_valid = split[1]\n",
    "        \n",
    "        print(\"#######################################\")\n",
    "        print(\"Training model number  \", i+1)\n",
    "        print(\"#######################################\")\n",
    "        print(\"\")\n",
    "        \n",
    "        print(\"Creating language model data bunch\")\n",
    "        print(\"\")\n",
    "        \n",
    "        fname = f\"cvfold{i+1}\"\n",
    "        data_lm = TextLMDataBunch.from_df(path / \"cv\" / fname,\n",
    "                                  train_df=df.iloc[i_train],\n",
    "                                  valid_df=df.iloc[i_valid])\n",
    "        \n",
    "        print(\"Creating classifier data bunch\")\n",
    "        print(\"\")\n",
    "        \n",
    "        data_clas = TextClasDataBunch.from_df(path / \"cv\" / fname,\n",
    "                                      train_df=df.iloc[i_train],\n",
    "                                      valid_df=df.iloc[i_valid],\n",
    "                                      vocab=data_lm.train_ds.vocab,\n",
    "                                      bs=8)\n",
    "        print(\"Finetuning language model\")\n",
    "        print(\"\")\n",
    "        learn = RNNLearner.language_model(data_lm, pretrained_model=URLs.WT103, drop_mult=0.5)\n",
    "        learn.fit_one_cycle(epochs, 1e-2)\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, 1e-3)\n",
    "        \n",
    "        ename = f\"ft_enc{i+1}\"\n",
    "        learn.save_encoder(ename)\n",
    "        \n",
    "        print(\"Training classifier\")\n",
    "        print(\"\")\n",
    "        learn = RNNLearner.classifier(data_clas, drop_mult=0.5)\n",
    "        learn.load_encoder(ename)\n",
    "        learn.fit_one_cycle(epochs, 1e-2)\n",
    "        learn.freeze_to(-2)\n",
    "        learn.fit_one_cycle(epochs, slice(5e-3/2., 5e-3))\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, slice(2e-3/100, 2e-3))\n",
    "        \n",
    "        train_perf = learn.validate(learn.data.train_dl)\n",
    "        valid_perf = learn.recorder.metrics\n",
    "        \n",
    "        fitted_clfs.append(FittedLearner(learn, train_perf, valid_perf))\n",
    "    \n",
    "    return fitted_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T22:17:56.673556Z",
     "start_time": "2018-11-01T22:17:26.043409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_learners = fit_ensemble_fastai(path, data, s, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_learners[0].learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, fl in enumerate(fitted_learners):\n",
    "    print(f\"Results for Model Number {i+1}:\")\n",
    "    print(f\"Train acc: {fl.train_perf}\")\n",
    "    print(f\"Valid acc: {fl.valid_perf}\")\n",
    "    fl.learner.recorder.plot_metrics()\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:37:56.767829Z",
     "start_time": "2018-10-21T17:37:56.757286Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\" Simple class holding data and functionality related to evaluating a classifier's performance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, scores):\n",
    "        self.df = pd.DataFrame({\"text\": texts, \"label\": labels, \"score\": scores})\n",
    "        self.group_means = self.df.groupby(by=\"label\").mean()\n",
    "        \n",
    "    def get_scores(self, thresholds=[0.25, 0.5, 0.75]):\n",
    "        if isinstance(thresholds, float):\n",
    "            thresholds = [thresholds]\n",
    "        \n",
    "        tps = [1e-8]*len(thresholds)  # True positives\n",
    "        fps = [1e-8]*len(thresholds)  # False positives\n",
    "        fns = [1e-8]*len(thresholds)  # False negatives\n",
    "        tns = [1e-8]*len(thresholds)  # True negatives\n",
    "        \n",
    "        for i, t in enumerate(thresholds):\n",
    "            for truth, pred in zip(self.df[\"label\"], self.df[\"score\"] > t):\n",
    "                if truth and pred:\n",
    "                    tps[i] += 1.\n",
    "                elif not truth and pred:\n",
    "                    fps[i] += 1.\n",
    "                elif truth and not pred:\n",
    "                    fns[i] += 1.\n",
    "                elif not truth and not pred:\n",
    "                    tns[i] += 1.\n",
    "        \n",
    "        precisions = [tp / (tp + fp) for tp, fp in zip(tps, fps)]\n",
    "        recalls = [tp / (tp + fn) for tp, fn in zip(tps, fns)]\n",
    "        f_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]\n",
    "        accuracies = [(tp + tn) / (tp + fp + fn + tn) for tp, fp, fn, tn in zip(tps, fps, fns, tns)]\n",
    "        \n",
    "        score_df = pd.DataFrame({\"threshold\": thresholds,\n",
    "                                 \"precision\": precisions,\n",
    "                                 \"recall\": recalls,\n",
    "                                 \"f_score\": f_scores,\n",
    "                                 \"accuracy\": accuracies})\n",
    "        \n",
    "        print(score_df)\n",
    "        self.score_df = score_df\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:06.430797Z",
     "start_time": "2018-10-21T17:38:06.417832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator = CustomEvaluator(X_text_test, y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:07.477180Z",
     "start_time": "2018-10-21T17:38:07.465921Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:10.097825Z",
     "start_time": "2018-10-21T17:38:10.081271Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:medium-classifier]",
   "language": "python",
   "name": "conda-env-medium-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
