{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T12:44:47.541623Z",
     "start_time": "2018-10-24T12:44:44.069657Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# debugging\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "# file system navigation\n",
    "from pathlib import Path\n",
    "\n",
    "# data transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# ml algorithms and evaluation metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from scipy.stats.distributions import uniform, randint\n",
    "\n",
    "# sklearn specific stuff\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# nlp\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import spacy\n",
    "from spacy.pipeline import TextCategorizer\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.util import decaying\n",
    "\n",
    "# misc\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_scores(model, X, y, n_cv=10):\n",
    "    precision_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"precision\")\n",
    "    recall_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"recall\")\n",
    "    print(f\"Average precision score for {n_cv} splits: {precision_scores.mean():.2f} (+/- {precision_scores.std():.2f})\")\n",
    "    print(f\"Average recall score for {n_cv} splits: {recall_scores.mean():.2f} (+/- {recall_scores.std() * 2:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:23:53.465807Z",
     "start_time": "2018-10-21T16:23:53.459929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_score_auc(model, X, y, n_cv=10):\n",
    "    auc_scores = cross_val_score(model, X, y, cv=n_cv, scoring=\"roc_auc\")\n",
    "    print(f\"Average auc score for {n_cv} splits: {auc_scores.mean():.2f} (+/- {auc_scores.std():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:42.909551Z",
     "start_time": "2018-10-23T16:13:42.903097Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_cv_auc(model, X, y, n_cv=10):\n",
    "    auc_cv = cross_validate(model, X, y,\n",
    "                                scoring=\"roc_auc\",\n",
    "                                cv=n_cv,\n",
    "                                n_jobs=-1,\n",
    "                                return_train_score=False,\n",
    "                                return_estimator=True)\n",
    "    auc_scores = auc_cv[\"test_score\"]\n",
    "    mean_auc = auc_scores.mean()\n",
    "    representative_estimator = auc_cv[\"estimator\"][np.argmin([np.abs(score - mean_auc) for score in auc_scores])]\n",
    "    print(f\"Average auc score for {n_cv} splits: {mean_auc:.2f} (+/- {auc_scores.std():.2f})\")\n",
    "    \n",
    "    return representative_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T16:49:35.059330Z",
     "start_time": "2018-10-21T16:49:35.049853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall(model, X, y):\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y, model.predict_proba(X)[:, 1])\n",
    "\n",
    "    step_kwargs = {\"step\": \"post\"}\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where=\"post\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall curve\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load preprocessed training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T12:45:11.133224Z",
     "start_time": "2018-10-24T12:45:10.828240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_parquet(Path.cwd() / \"data\" / \"processed\" / \"train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:12:51.232222Z",
     "start_time": "2018-10-23T16:12:51.206645Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:12:52.062238Z",
     "start_time": "2018-10-23T16:12:52.054623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:16.555610Z",
     "start_time": "2018-10-23T16:13:16.549837Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_base = data[[\"claps\", \"reading_time\", \"interesting\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Visualize data distribution for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "target_names = [\"not interesting\", \"interesting\"]\n",
    "\n",
    "colors = [\"red\", \"green\"]\n",
    "\n",
    "for label, color in zip(range(len(data_base[\"interesting\"])), colors):\n",
    "    plt.scatter(np.array(data_base[data_base[\"interesting\"]==label].iloc[:, x_index]), \n",
    "                np.array(data_base[data_base[\"interesting\"]==label].iloc[:, y_index]),\n",
    "                label=target_names[label],\n",
    "                c=color)\n",
    "\n",
    "plt.xlabel(data_base.columns[x_index])\n",
    "plt.ylabel(data_base.columns[y_index])\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(wd, \"output\", \"base_classifier.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Baseline classficiation model using author, claps and reading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:15:34.492706Z",
     "start_time": "2018-10-23T16:15:34.485422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_num = data_base[[\"claps\", \"reading_time\"]]\n",
    "y_num = data_base[\"interesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:13:56.804070Z",
     "start_time": "2018-10-23T16:13:53.798814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_model = get_cv_auc(RandomForestClassifier(), X_num, y, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:21:28.607292Z",
     "start_time": "2018-10-23T16:21:28.601934Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = model_selection.StratifiedShuffleSplit(n_splits=4, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T16:32:32.143735Z",
     "start_time": "2018-10-23T16:32:32.073254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, split in enumerate(s.split(X_num, y_num)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    print(\"Training model number  \", i)\n",
    "    rf_model.fit(X_num.iloc[i_train, :], y_num[i_train])\n",
    "    print(\"AUC on the test set:\")\n",
    "    print(metrics.roc_auc_score(y_num[i_test], rf_model.predict_proba(X_num.iloc[i_test, :])[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Text based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T12:45:20.557778Z",
     "start_time": "2018-10-24T12:45:20.552611Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_text = data[\"text\"]\n",
    "y = data[\"interesting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create true hold out set to simulate future articles coming in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:20:47.213764Z",
     "start_time": "2018-10-24T13:20:47.208360Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_text[0:70]\n",
    "y_70 = y[0:70]\n",
    "\n",
    "X_100 = X_text[70:]\n",
    "y_100 = y[70:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:24:47.508398Z",
     "start_time": "2018-10-24T13:24:47.496691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_70 = X_70.reset_index().drop(\"index\", axis=1)[\"text\"]\n",
    "X_100 = X_100.reset_index().drop(\"index\", axis=1)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:25:34.020042Z",
     "start_time": "2018-10-24T13:25:34.009723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_70 = y_70.reset_index().drop(\"index\", axis=1)[\"interesting\"]\n",
    "y_100 = y_100.reset_index().drop(\"index\", axis=1)[\"interesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T17:16:28.204341Z",
     "start_time": "2018-10-23T17:16:28.198673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X_text,\n",
    "                                                              y,\n",
    "                                                              test_size=0.3,\n",
    "                                                              random_state=42,\n",
    "                                                              stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CountVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:55.179691Z",
     "start_time": "2018-10-21T17:10:55.173740Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:55.881558Z",
     "start_time": "2018-10-21T17:10:55.874917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(vectorizer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:58.877105Z",
     "start_time": "2018-10-21T17:10:56.454940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:10:59.048427Z",
     "start_time": "2018-10-21T17:10:58.880179Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Some optimization, i.e. preprocessing and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:29.267522Z",
     "start_time": "2018-10-21T17:09:29.256534Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", CountVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000)}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=8,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=10,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.021782Z",
     "start_time": "2018-10-21T17:09:32.004989Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = grid.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.032580Z",
     "start_time": "2018-10-21T17:09:50.025314Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_auc = grid.cv_results_[\"mean_test_score\"].mean()\n",
    "std_auc = grid.cv_results_[\"std_test_score\"].mean()\n",
    "print(f\"Average auc score: {avg_auc:.2f} (+/- {std_auc:.2f})\")\n",
    "# pd.DataFrame.from_dict(grid.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:09:50.477014Z",
     "start_time": "2018-10-21T17:09:50.036911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(grid.best_estimator_, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### TfidfVectorizer + random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:37.929166Z",
     "start_time": "2018-10-21T17:11:37.923525Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:38.678393Z",
     "start_time": "2018-10-21T17:11:38.672003Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(vectorizer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.554118Z",
     "start_time": "2018-10-21T17:11:42.077385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:11:44.713209Z",
     "start_time": "2018-10-21T17:11:44.557498Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:03.112478Z",
     "start_time": "2018-10-21T17:23:56.079623Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 3), max_df=0.8, min_df=0.2, max_features=5000)\n",
    "\n",
    "pipe = make_pipeline(vectorizer, RandomForestClassifier())\n",
    "\n",
    "estimator = get_cv_auc(pipe, X_text_train, y_train, n_cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:24:05.661623Z",
     "start_time": "2018-10-21T17:24:05.156724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(estimator, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:25.557203Z",
     "start_time": "2018-10-21T17:20:25.541996Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vec\", TfidfVectorizer()),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "    ])\n",
    "params = {\"vec__stop_words\": [\"english\", None],\n",
    "          \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"vec__max_df\": uniform(loc=0.8, scale=0.2),\n",
    "          \"vec__min_df\": uniform(loc=0.0, scale=0.2),\n",
    "          \"vec__max_features\": randint(low=1000, high=9000)}\n",
    "\n",
    "grid = RandomizedSearchCV(pipe,\n",
    "                          params,\n",
    "                          n_iter=8,\n",
    "                          scoring=\"roc_auc\",\n",
    "                          n_jobs=-1,\n",
    "                          cv=10,\n",
    "                          return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.325253Z",
     "start_time": "2018-10-21T17:20:28.199477Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = grid.fit(X_text_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.337135Z",
     "start_time": "2018-10-21T17:20:50.330807Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_auc = grid.cv_results_[\"mean_test_score\"].mean()\n",
    "std_auc = grid.cv_results_[\"std_test_score\"].mean()\n",
    "print(f\"Average auc score: {avg_auc:.2f} (+/- {std_auc:.2f})\")\n",
    "# pd.DataFrame.from_dict(grid.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:20:50.752909Z",
     "start_time": "2018-10-21T17:20:50.349418Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_precision_recall(grid.best_estimator_, X_text_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Advanced tokenization and lemmatization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:24:12.630133Z",
     "start_time": "2018-10-24T15:24:11.163316Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:24:32.158176Z",
     "start_time": "2018-10-24T15:24:31.110958Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T15:32:02.077992Z",
     "start_time": "2018-10-24T15:31:59.682984Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T14:52:53.664047Z",
     "start_time": "2018-10-24T14:52:53.144816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Instructions from SpaCy documentation](https://spacy.io/usage/training#section-textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:12:12.319192Z",
     "start_time": "2018-10-24T13:12:12.305748Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomSpacyClassifier():\n",
    "    \"\"\" Wrapper for spaCy's text classification that enables integration with sklearn.metrics.cross_validate\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._estimator_type = \"classifier\"\n",
    "        \n",
    "        self.nlp = None\n",
    "        self.label = None\n",
    "        self.train_data = None\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return dict()\n",
    "    \n",
    "    def add_textcat(self, label):\n",
    "        self.label = label\n",
    "        if \"textcat\" not in self.nlp.pipe_names:\n",
    "            textcat = self.nlp.create_pipe(\"textcat\")\n",
    "            self.nlp.add_pipe(textcat, last=True)\n",
    "        # otherwise, get it, so we can add labels to it\n",
    "        else:\n",
    "            textcat = self.nlp.get_pipe(\"textcat\")\n",
    "        textcat.add_label(label)\n",
    "    \n",
    "    def fit(self, X, y, n_iter=10, **kwargs):\n",
    "        \n",
    "        self.nlp = spacy.load(\"en\")\n",
    "        self.add_textcat(\"interesting\")\n",
    "        self.train_data = [(e, {\"cats\": {self.label: bool(l)}}) for e, l in zip(X, y)]\n",
    "        \n",
    "        drop_rate = kwargs[\"drop_rate\"]\n",
    "        \n",
    "        other_pipes = [pipe for pipe in self.nlp.pipe_names if pipe != \"textcat\"]\n",
    "        with self.nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "            optimizer = self.nlp.begin_training()\n",
    "            for i in range(n_iter):\n",
    "                print(f\"EPOCH {i+1}\")\n",
    "                losses = {}\n",
    "                batches = minibatch(self.train_data, size=compounding(4., 16., 1.001))\n",
    "                for batch in batches:\n",
    "                    texts, annotations = zip(*batch)\n",
    "                    self.nlp.update(texts, annotations, sgd=optimizer, drop=drop_rate,\n",
    "                               losses=losses)\n",
    "                loss = losses[\"textcat\"]\n",
    "                print(f\"LOSS: {loss}\")\n",
    "                print(\"\")\n",
    "                \n",
    "    def predict_proba(self, X):\n",
    "        p1_scores = [np.float64(self.nlp(sample_text).cats[\"interesting\"]) for sample_text in X]\n",
    "        \n",
    "        return np.array([[1. - score, score] for score in p1_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:12:12.948562Z",
     "start_time": "2018-10-24T13:12:12.944275Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clf = CustomSpacyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:12:13.559633Z",
     "start_time": "2018-10-24T13:12:13.555439Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s = model_selection.StratifiedShuffleSplit(n_splits=6, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train several custom classifiers and evaluate their performance on the true hold out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:11.842938Z",
     "start_time": "2018-10-24T13:26:07.503373Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fitted_clfs = []\n",
    "\n",
    "for i, split in enumerate(s.split(X_70, y_70)):\n",
    "    i_train = split[0]\n",
    "    i_test = split[1]\n",
    "    \n",
    "    print(\"Training model number  \", i)\n",
    "    print(\"\")\n",
    "    print(\"Training IDs: \", i_train)\n",
    "    print(\"Test IDs: \", i_test)\n",
    "    \n",
    "    clf.fit(X_70[i_train], y_70[i_train], n_iter=5, drop_rate=0.4)\n",
    "    fitted_clf = copy.deepcopy(clf)\n",
    "    test_auc = metrics.roc_auc_score(y_70[i_test], clf.predict_proba(X_70[i_test])[:, 1])\n",
    "    fitted_clfs.append((fitted_clf, test_auc))\n",
    "\n",
    "    print(\"AUC on the test set: \", test_auc)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:29:29.229181Z",
     "start_time": "2018-10-24T13:29:29.222974Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = [score for _, score in fitted_clfs]\n",
    "print(\"Mean AUC: \", np.mean(scores))\n",
    "print(\"Std deviation of AUC: \", np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.242453Z",
     "start_time": "2018-10-24T13:29:31.223222Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = np.array([c.predict_proba(X_100)[:, 1] for c, _ in fitted_clfs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T13:31:33.257840Z",
     "start_time": "2018-10-24T13:31:33.245011Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"AUC on the hold out set: \", metrics.roc_auc_score(y_100, preds.mean(axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:41.728665Z",
     "start_time": "2018-10-21T19:08:15.508664Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_cv = cross_validate(clf, X_text_train, y_train,\n",
    "                            scoring=\"roc_auc\",\n",
    "                            cv=2,\n",
    "                            n_jobs=1,\n",
    "                            return_train_score=False,\n",
    "                            return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T19:09:48.231686Z",
     "start_time": "2018-10-21T19:09:48.222714Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "auc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:28.110965Z",
     "start_time": "2018-10-21T17:25:27.194211Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:32.274827Z",
     "start_time": "2018-10-21T17:25:32.269573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.create_pipe(\"textcat\")\n",
    "    nlp.add_pipe(textcat, last=True)\n",
    "# otherwise, get it, so we can add labels to it\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:34.572100Z",
     "start_time": "2018-10-21T17:25:34.562167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "textcat.add_label(\"interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:25:39.933733Z",
     "start_time": "2018-10-21T17:25:39.926488Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = [(example, {\"cats\": {\"interesting\": bool(label)}}) for example, label in zip(X_text_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:26:16.087658Z",
     "start_time": "2018-10-21T17:26:16.080752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# dropout = decaying(0.6, 0.2, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(dropout))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=compounding(4., 16., 1.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < 20:\n",
    "    print(next(size))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.5))\n",
    "        print(len(next(batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:08.202431Z",
     "start_time": "2018-10-21T17:26:17.696164Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    for i in range(n_iter):\n",
    "        print(f\"EPOCH {i+1}\")\n",
    "        losses = {}\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 16., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.3,\n",
    "                       losses=losses)\n",
    "        loss = losses[\"textcat\"]\n",
    "        print(f\"LOSS: {loss}\")\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:27:41.161981Z",
     "start_time": "2018-10-21T17:27:28.334154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_scores = [nlp(sample_text).cats[\"interesting\"] for sample_text in X_text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:38.544596Z",
     "start_time": "2018-10-21T18:36:37.938629Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te = [np.float64(nlp(sample_text).cats[\"interesting\"]) for sample_text in X_text_test[0:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.001249Z",
     "start_time": "2018-10-21T18:34:35.997389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2 = np.array([[1. - score, score] for score in te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:34:36.546165Z",
     "start_time": "2018-10-21T18:34:36.539196Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "te2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T18:36:52.812941Z",
     "start_time": "2018-10-21T18:36:52.802279Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.float64(te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:29:17.285373Z",
     "start_time": "2018-10-21T17:29:17.277144Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:30:21.381422Z",
     "start_time": "2018-10-21T17:30:21.260650Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = metrics.precision_recall_curve(y_test, test_scores)\n",
    "\n",
    "step_kwargs = {\"step\": \"post\"}\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where=\"post\")\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title(\"Precision-Recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:37:56.767829Z",
     "start_time": "2018-10-21T17:37:56.757286Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class CustomEvaluator():\n",
    "    \"\"\" Simple class holding data and functionality related to evaluating a classifier's performance\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, scores):\n",
    "        self.df = pd.DataFrame({\"text\": texts, \"label\": labels, \"score\": scores})\n",
    "        self.group_means = self.df.groupby(by=\"label\").mean()\n",
    "        \n",
    "    def get_scores(self, thresholds=[0.25, 0.5, 0.75]):\n",
    "        if isinstance(thresholds, float):\n",
    "            thresholds = [thresholds]\n",
    "        \n",
    "        tps = [1e-8]*len(thresholds)  # True positives\n",
    "        fps = [1e-8]*len(thresholds)  # False positives\n",
    "        fns = [1e-8]*len(thresholds)  # False negatives\n",
    "        tns = [1e-8]*len(thresholds)  # True negatives\n",
    "        \n",
    "        for i, t in enumerate(thresholds):\n",
    "            for truth, pred in zip(self.df[\"label\"], self.df[\"score\"] > t):\n",
    "                if truth and pred:\n",
    "                    tps[i] += 1.\n",
    "                elif not truth and pred:\n",
    "                    fps[i] += 1.\n",
    "                elif truth and not pred:\n",
    "                    fns[i] += 1.\n",
    "                elif not truth and not pred:\n",
    "                    tns[i] += 1.\n",
    "        \n",
    "        precisions = [tp / (tp + fp) for tp, fp in zip(tps, fps)]\n",
    "        recalls = [tp / (tp + fn) for tp, fn in zip(tps, fns)]\n",
    "        f_scores = [2 * (p * r) / (p + r) for p, r in zip(precisions, recalls)]\n",
    "        accuracies = [(tp + tn) / (tp + fp + fn + tn) for tp, fp, fn, tn in zip(tps, fps, fns, tns)]\n",
    "        \n",
    "        score_df = pd.DataFrame({\"threshold\": thresholds,\n",
    "                                 \"precision\": precisions,\n",
    "                                 \"recall\": recalls,\n",
    "                                 \"f_score\": f_scores,\n",
    "                                 \"accuracy\": accuracies})\n",
    "        \n",
    "        print(score_df)\n",
    "        self.score_df = score_df\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:06.430797Z",
     "start_time": "2018-10-21T17:38:06.417832Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator = CustomEvaluator(X_text_test, y_test, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:07.477180Z",
     "start_time": "2018-10-21T17:38:07.465921Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.group_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-21T17:38:10.097825Z",
     "start_time": "2018-10-21T17:38:10.081271Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_evaluator.get_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:medium-classifier]",
   "language": "python",
   "name": "conda-env-medium-classifier-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
